{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database libraries\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct PostgreSQL connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Direct psycopg2 connection\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def get_connection():\n",
    "    return psycopg2.connect(\n",
    "        host='localhost',\n",
    "        port=5432,\n",
    "        database='city_marketing',\n",
    "        user='postgres',\n",
    "        password='1234'\n",
    "    )\n",
    "\n",
    "try:\n",
    "    # Test connection\n",
    "    conn = get_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT 1\")\n",
    "    print(\"Direct PostgreSQL connection successful!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Direct connection failed: {e}\")\n",
    "    print(\"Let's check container status...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 10000 bike counter records\n",
      "Dataset shape: (10000, 11)\n",
      "Columns: ['counter_name', 'installation_date', 'count_datetime', 'hourly_count', 'coordinates', 'month_year', 'id_compteur', 'counter', 'name', 'id', 'arrondissement']\n",
      "\n",
      "First 3 rows:\n",
      "                         counter_name installation_date  \\\n",
      "0  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "1  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "2  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "\n",
      "             count_datetime  hourly_count                        coordinates  \\\n",
      "0 2024-05-01 03:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "1 2024-05-01 04:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "2 2024-05-01 05:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "\n",
      "  month_year          id_compteur      counter                          name  \\\n",
      "0    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "1    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "2    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "\n",
      "          id arrondissement  \n",
      "0  100003098             10  \n",
      "1  100003098             10  \n",
      "2  100003098             10  \n"
     ]
    }
   ],
   "source": [
    "# Load bike counter data - simple direct approach\n",
    "conn = get_connection()\n",
    "bike_data = pd.read_sql(\"SELECT * FROM bike_counters\", conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"✅ Loaded {len(bike_data)} bike counter records\")\n",
    "\n",
    "# Quick data overview\n",
    "print(f\"Dataset shape: {bike_data.shape}\")\n",
    "print(f\"Columns: {list(bike_data.columns)}\")\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(bike_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET OVERVIEW\n",
      "==================================================\n",
      "Shape: (10000, 11)\n",
      "Memory usage: 5.23 MB\n",
      "\n",
      "Column Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   counter_name       10000 non-null  object             \n",
      " 1   installation_date  10000 non-null  datetime64[ns]     \n",
      " 2   count_datetime     10000 non-null  datetime64[ns, UTC]\n",
      " 3   hourly_count       10000 non-null  int64              \n",
      " 4   coordinates        10000 non-null  object             \n",
      " 5   month_year         10000 non-null  object             \n",
      " 6   id_compteur        10000 non-null  object             \n",
      " 7   counter            10000 non-null  object             \n",
      " 8   name               10000 non-null  object             \n",
      " 9   id                 10000 non-null  object             \n",
      " 10  arrondissement     10000 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), int64(1), object(8)\n",
      "memory usage: 859.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic data info\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {bike_data.shape}\")\n",
    "print(f\"Memory usage: {bike_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nColumn Information:\")\n",
    "print(bike_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE DATA\n",
      "==================================================\n",
      "                         counter_name installation_date  \\\n",
      "0  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "1  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "2  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "3  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "4  106 avenue Denfert Rochereau NE-SO        2012-02-22   \n",
      "\n",
      "             count_datetime  hourly_count                        coordinates  \\\n",
      "0 2024-05-01 03:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "1 2024-05-01 04:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "2 2024-05-01 05:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "3 2024-05-01 08:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "4 2024-05-01 09:00:00+00:00             0  {'lon': 2.33305, 'lat': 48.83507}   \n",
      "\n",
      "  month_year          id_compteur      counter                          name  \\\n",
      "0    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "1    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "2    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "3    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "4    2024-05  100003098-101003098  Y2H20114504  106 avenue Denfert Rochereau   \n",
      "\n",
      "          id arrondissement  \n",
      "0  100003098             10  \n",
      "1  100003098             10  \n",
      "2  100003098             10  \n",
      "3  100003098             10  \n",
      "4  100003098             10  \n",
      "\n",
      "COLUMN NAMES:\n",
      "['counter_name', 'installation_date', 'count_datetime', 'hourly_count', 'coordinates', 'month_year', 'id_compteur', 'counter', 'name', 'id', 'arrondissement']\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"SAMPLE DATA\")\n",
    "print(\"=\" * 50)\n",
    "print(bike_data.head())\n",
    "\n",
    "print(\"\\nCOLUMN NAMES:\")\n",
    "print(list(bike_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES ANALYSIS\n",
      "==================================================\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Missing_Count': bike_data.isnull().sum(),\n",
    "    'Missing_Percentage': (bike_data.isnull().sum() / len(bike_data)) * 100\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "missing_with_values = missing_analysis[missing_analysis['Missing_Count'] > 0]\n",
    "if not missing_with_values.empty:\n",
    "    print(missing_with_values)\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE VALUES ANALYSIS\n",
      "==================================================\n",
      "Key columns found: ['counter_name', 'arrondissement', 'month_year', 'id_compteur', 'name', 'counter']\n",
      "\n",
      "counter_name: 4 unique values\n",
      "  Sample values: ['106 avenue Denfert Rochereau NE-SO', '135 avenue Daumesnil SE-NO', '28 boulevard Diderot E-O', '28 boulevard Diderot O-E']\n",
      "\n",
      "arrondissement: 3 unique values\n",
      "  Sample values: ['10', '13', '28']\n",
      "\n",
      "month_year: 14 unique values\n",
      "  Sample values: ['2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12', '2025-01', '2025-02']\n",
      "\n",
      "id_compteur: 4 unique values\n",
      "  Sample values: ['100003098-101003098', '100006300-101006300', '100007049-102007049', '100007049-101007049']\n",
      "\n",
      "name: 3 unique values\n",
      "  Sample values: ['106 avenue Denfert Rochereau', '135 avenue Daumesnil', '28 boulevard Diderot']\n",
      "\n",
      "counter: 3 unique values\n",
      "  Sample values: ['Y2H20114504', 'X2H18086316', 'Y2H21015011']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unique values in key columns\n",
    "print(\"UNIQUE VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check what columns we actually have\n",
    "key_columns = []\n",
    "possible_cols = ['counter_name', 'arrondissement', 'month_year', 'id_compteur', 'name', 'counter']\n",
    "\n",
    "for col in possible_cols:\n",
    "    if col in bike_data.columns:\n",
    "        key_columns.append(col)\n",
    "\n",
    "print(f\"Key columns found: {key_columns}\")\n",
    "print()\n",
    "\n",
    "for col in key_columns:\n",
    "    unique_count = bike_data[col].nunique()\n",
    "    print(f\"{col}: {unique_count} unique values\")\n",
    "    if unique_count < 20:\n",
    "        print(f\"  Sample values: {list(bike_data[col].unique())[:10]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPORAL ANALYSIS\n",
      "==================================================\n",
      "Data timespan: 2024-05-01 03:00:00+00:00 to 2025-06-04 21:00:00+00:00\n",
      "Total months covered: 14\n",
      "\n",
      "Records by month:\n",
      "month_year\n",
      "2024-05    954\n",
      "2024-06    763\n",
      "2024-07    714\n",
      "2024-08    724\n",
      "2024-09    733\n",
      "2024-10    789\n",
      "2024-11    759\n",
      "2024-12    734\n",
      "2025-01    755\n",
      "2025-02    719\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert datetime columns and analyze temporal patterns\n",
    "print(\"TEMPORAL ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convert date columns\n",
    "bike_data['count_datetime'] = pd.to_datetime(bike_data['count_datetime'])\n",
    "bike_data['installation_date'] = pd.to_datetime(bike_data['installation_date'])\n",
    "\n",
    "# Analyze temporal coverage\n",
    "print(f\"Data timespan: {bike_data['count_datetime'].min()} to {bike_data['count_datetime'].max()}\")\n",
    "print(f\"Total months covered: {bike_data['count_datetime'].dt.to_period('M').nunique()}\")\n",
    "\n",
    "# Extract time components for analysis\n",
    "bike_data['year'] = bike_data['count_datetime'].dt.year\n",
    "bike_data['month'] = bike_data['count_datetime'].dt.month\n",
    "bike_data['day'] = bike_data['count_datetime'].dt.day\n",
    "bike_data['hour'] = bike_data['count_datetime'].dt.hour\n",
    "bike_data['weekday'] = bike_data['count_datetime'].dt.day_name()\n",
    "\n",
    "# Monthly distribution\n",
    "monthly_dist = bike_data['month_year'].value_counts().sort_index()\n",
    "print(f\"\\nRecords by month:\")\n",
    "print(monthly_dist.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOGRAPHIC DISTRIBUTION ANALYSIS\n",
      "==================================================\n",
      "Records by Arrondissement:\n",
      "  arrondissement  record_count\n",
      "1             10          3228\n",
      "2             13          3193\n",
      "0             28          3579\n",
      "\n",
      "Coverage Analysis:\n",
      "• Arrondissements monitored: 3/20 (15.0%)\n",
      "• Strategic focus areas: 10, 13, 28\n",
      "\n",
      "🎯 Area Characteristics:\n",
      "• Arr. 10: 3,228 records - République/Canal Saint-Martin - Trendy area, high foot traffic\n",
      "• Arr. 13: 3,193 records - Chinatown/Bibliothèque - Diverse, emerging area\n",
      "• Arr. 28: 3,579 records - Not a Paris arrondissement - possibly suburban counter\n"
     ]
    }
   ],
   "source": [
    "# Geographic analysis using arrondissement\n",
    "print(\"GEOGRAPHIC DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Clean arrondissement data\n",
    "bike_data['arrondissement_clean'] = bike_data['arrondissement'].astype(str).str.strip()\n",
    "\n",
    "# Arrondissement distribution\n",
    "arr_distribution = bike_data['arrondissement_clean'].value_counts().reset_index()\n",
    "arr_distribution.columns = ['arrondissement', 'record_count']\n",
    "arr_distribution = arr_distribution.sort_values('arrondissement')\n",
    "\n",
    "print(\"Records by Arrondissement:\")\n",
    "print(arr_distribution)\n",
    "\n",
    "# Calculate coverage insights\n",
    "total_paris_arrondissements = 20\n",
    "covered_arr = len(arr_distribution)\n",
    "coverage_percentage = (covered_arr / total_paris_arrondissements) * 100\n",
    "\n",
    "print(f\"\\nCoverage Analysis:\")\n",
    "print(f\"• Arrondissements monitored: {covered_arr}/20 ({coverage_percentage:.1f}%)\")\n",
    "print(f\"• Strategic focus areas: {', '.join(arr_distribution['arrondissement'].tolist())}\")\n",
    "\n",
    "# Check if these are high-activity areas (commercial/tourist zones)\n",
    "arr_insights = {\n",
    "    '10': 'République/Canal Saint-Martin - Trendy area, high foot traffic',\n",
    "    '13': 'Chinatown/Bibliothèque - Diverse, emerging area',\n",
    "    '28': 'Not a Paris arrondissement - possibly suburban counter'\n",
    "}\n",
    "\n",
    "print(f\"\\n🎯 Area Characteristics:\")\n",
    "for arr in arr_distribution['arrondissement']:\n",
    "    insight = arr_insights.get(arr, 'Unknown area characteristics')\n",
    "    records = arr_distribution[arr_distribution['arrondissement'] == arr]['record_count'].iloc[0]\n",
    "    print(f\"• Arr. {arr}: {records:,} records - {insight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTER INFRASTRUCTURE ANALYSIS\n",
      "==================================================\n",
      "Counter Details:\n",
      "                         counter_name arrondissement_clean  \\\n",
      "0  106 avenue Denfert Rochereau NE-SO                   10   \n",
      "1          135 avenue Daumesnil SE-NO                   13   \n",
      "2            28 boulevard Diderot E-O                   28   \n",
      "3            28 boulevard Diderot O-E                   28   \n",
      "\n",
      "              first_reading              last_reading  total_readings  \\\n",
      "0 2024-05-01 03:00:00+00:00 2025-06-04 21:00:00+00:00            3228   \n",
      "1 2024-05-01 07:00:00+00:00 2025-06-04 21:00:00+00:00            3193   \n",
      "2 2024-05-01 04:00:00+00:00 2025-06-04 21:00:00+00:00            3296   \n",
      "3 2024-05-01 04:00:00+00:00 2024-06-07 06:00:00+00:00             283   \n",
      "\n",
      "                           coordinates  \n",
      "0    {'lon': 2.33305, 'lat': 48.83507}  \n",
      "1  {'lon': 2.383378, 'lat': 48.843435}  \n",
      "2    {'lon': 2.37559, 'lat': 48.84613}  \n",
      "3    {'lon': 2.37559, 'lat': 48.84613}  \n",
      "\n",
      "Monitoring Intensity:\n",
      "• 106 avenue Denfert Rochereau NE-SO\n",
      "  Location: Arr. 10 | Readings: 3,228 | Duration: 399 days\n",
      "  Avg readings/day: 8.1\n",
      "\n",
      "• 135 avenue Daumesnil SE-NO\n",
      "  Location: Arr. 13 | Readings: 3,193 | Duration: 399 days\n",
      "  Avg readings/day: 8.0\n",
      "\n",
      "• 28 boulevard Diderot E-O\n",
      "  Location: Arr. 28 | Readings: 3,296 | Duration: 399 days\n",
      "  Avg readings/day: 8.3\n",
      "\n",
      "• 28 boulevard Diderot O-E\n",
      "  Location: Arr. 28 | Readings: 283 | Duration: 37 days\n",
      "  Avg readings/day: 7.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed counter analysis\n",
    "print(\"COUNTER INFRASTRUCTURE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Unique counters and their characteristics\n",
    "unique_counters = bike_data.groupby(['counter_name', 'arrondissement_clean']).agg({\n",
    "    'count_datetime': ['min', 'max', 'count'],\n",
    "    'coordinates': 'first'\n",
    "}).round(2)\n",
    "\n",
    "unique_counters.columns = ['first_reading', 'last_reading', 'total_readings', 'coordinates']\n",
    "unique_counters = unique_counters.reset_index()\n",
    "\n",
    "print(\"Counter Details:\")\n",
    "print(unique_counters)\n",
    "\n",
    "# Calculate monitoring intensity\n",
    "print(f\"\\nMonitoring Intensity:\")\n",
    "for _, counter in unique_counters.iterrows():\n",
    "    name = counter['counter_name'][:40] + \"...\" if len(counter['counter_name']) > 40 else counter['counter_name']\n",
    "    arr = counter['arrondissement_clean']\n",
    "    readings = counter['total_readings']\n",
    "    duration = (pd.to_datetime(counter['last_reading']) - pd.to_datetime(counter['first_reading'])).days\n",
    "    \n",
    "    print(f\"• {name}\")\n",
    "    print(f\"  Location: Arr. {arr} | Readings: {readings:,} | Duration: {duration} days\")\n",
    "    if duration > 0:\n",
    "        print(f\"  Avg readings/day: {readings/duration:.1f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COORDINATE PROCESSING\n",
      "==================================================\n",
      "Successfully extracted coordinates: 10,000/10,000 records\n",
      "Latitude range: 48.8351 to 48.8461\n",
      "Longitude range: 2.3331 to 2.3834\n",
      "\n",
      "Unique counter locations: 4\n",
      "                         counter_name   latitude  longitude  records\n",
      "0  106 avenue Denfert Rochereau NE-SO  48.835070   2.333050     3228\n",
      "1          135 avenue Daumesnil SE-NO  48.843435   2.383378     3193\n",
      "2            28 boulevard Diderot E-O  48.846130   2.375590     3296\n",
      "3            28 boulevard Diderot O-E  48.846130   2.375590      283\n"
     ]
    }
   ],
   "source": [
    "# Process coordinates for mapping\n",
    "print(\"COORDINATE PROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def extract_lat_lon(coord_str):\n",
    "    \"\"\"Extract latitude and longitude from coordinate string\"\"\"\n",
    "    try:\n",
    "        if pd.isna(coord_str):\n",
    "            return None, None\n",
    "        \n",
    "        # Handle JSON-like string format\n",
    "        coord_str = str(coord_str).replace(\"'\", '\"')\n",
    "        import json\n",
    "        coord_dict = json.loads(coord_str)\n",
    "        \n",
    "        lat = coord_dict.get('lat', None)\n",
    "        lon = coord_dict.get('lon', None)\n",
    "        \n",
    "        return lat, lon\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# Apply coordinate extraction\n",
    "bike_data[['latitude', 'longitude']] = bike_data['coordinates'].apply(\n",
    "    lambda x: pd.Series(extract_lat_lon(x))\n",
    ")\n",
    "\n",
    "# Check coordinate success\n",
    "valid_coords = bike_data.dropna(subset=['latitude', 'longitude'])\n",
    "print(f\"Successfully extracted coordinates: {len(valid_coords):,}/{len(bike_data):,} records\")\n",
    "\n",
    "if len(valid_coords) > 0:\n",
    "    print(f\"Latitude range: {valid_coords['latitude'].min():.4f} to {valid_coords['latitude'].max():.4f}\")\n",
    "    print(f\"Longitude range: {valid_coords['longitude'].min():.4f} to {valid_coords['longitude'].max():.4f}\")\n",
    "    \n",
    "    # Unique locations\n",
    "    unique_locations = valid_coords.groupby(['counter_name', 'latitude', 'longitude']).size().reset_index(name='records')\n",
    "    print(f\"\\nUnique counter locations: {len(unique_locations)}\")\n",
    "    print(unique_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVITY PATTERN ANALYSIS\n",
      "==================================================\n",
      "Records by Hour of Day:\n",
      "hour\n",
      "0     411\n",
      "1     422\n",
      "2     391\n",
      "3     403\n",
      "4     400\n",
      "5     435\n",
      "6     415\n",
      "7     418\n",
      "8     410\n",
      "9     427\n",
      "10    424\n",
      "11    422\n",
      "12    384\n",
      "13    425\n",
      "14    401\n",
      "15    457\n",
      "16    425\n",
      "17    413\n",
      "18    424\n",
      "19    445\n",
      "20    413\n",
      "21    420\n",
      "22    408\n",
      "23    407\n",
      "dtype: int64\n",
      "\n",
      "Records by Day of Week:\n",
      "weekday\n",
      "Monday       1425\n",
      "Tuesday      1453\n",
      "Wednesday    1482\n",
      "Thursday     1409\n",
      "Friday       1421\n",
      "Saturday     1393\n",
      "Sunday       1417\n",
      "dtype: int64\n",
      "\n",
      "Monthly Trends:\n",
      "  year_month  records\n",
      "0    2024-05      957\n",
      "1    2024-06      762\n",
      "2    2024-07      714\n",
      "3    2024-08      724\n",
      "4    2024-09      735\n",
      "5    2024-10      785\n",
      "6    2024-11      760\n",
      "7    2024-12      733\n",
      "8    2025-01      756\n",
      "9    2025-02      718\n",
      "\n",
      "Counter Activity Ranking:\n",
      "                         counter_name arrondissement_clean  total_records\n",
      "2            28 boulevard Diderot E-O                   28           3296\n",
      "0  106 avenue Denfert Rochereau NE-SO                   10           3228\n",
      "1          135 avenue Daumesnil SE-NO                   13           3193\n",
      "3            28 boulevard Diderot O-E                   28            283\n"
     ]
    }
   ],
   "source": [
    "# Analyze activity patterns over time\n",
    "print(\"ACTIVITY PATTERN ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Hourly patterns\n",
    "hourly_activity = bike_data.groupby('hour').size()\n",
    "print(\"Records by Hour of Day:\")\n",
    "print(hourly_activity)\n",
    "\n",
    "# Daily patterns  \n",
    "daily_activity = bike_data.groupby('weekday').size()\n",
    "print(f\"\\nRecords by Day of Week:\")\n",
    "# Reorder to start with Monday\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_activity = daily_activity.reindex(day_order)\n",
    "print(daily_activity)\n",
    "\n",
    "# Monthly trends\n",
    "monthly_trends = bike_data.groupby(['year', 'month']).size().reset_index(name='records')\n",
    "monthly_trends['year_month'] = monthly_trends['year'].astype(str) + '-' + monthly_trends['month'].astype(str).str.zfill(2)\n",
    "print(f\"\\nMonthly Trends:\")\n",
    "print(monthly_trends[['year_month', 'records']].head(10))\n",
    "\n",
    "# Counter activity comparison\n",
    "counter_activity = bike_data.groupby(['counter_name', 'arrondissement_clean']).size().reset_index(name='total_records')\n",
    "counter_activity = counter_activity.sort_values('total_records', ascending=False)\n",
    "print(f\"\\nCounter Activity Ranking:\")\n",
    "print(counter_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. Arrondissement distribution\n",
    "axes[0,0].bar(arr_distribution['arrondissement'], arr_distribution['record_count'], color='skyblue')\n",
    "axes[0,0].set_title('Records by Arrondissement', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Arrondissement')\n",
    "axes[0,0].set_ylabel('Number of Records')\n",
    "for i, v in enumerate(arr_distribution['record_count']):\n",
    "    axes[0,0].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Hourly activity pattern\n",
    "axes[0,1].plot(hourly_activity.index, hourly_activity.values, marker='o', linewidth=2, markersize=6)\n",
    "axes[0,1].set_title('Activity Pattern by Hour', fontweight='bold')\n",
    "axes[0,1].set_xlabel('Hour of Day')\n",
    "axes[0,1].set_ylabel('Number of Records')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# 3. Daily pattern\n",
    "daily_activity.plot(kind='bar', ax=axes[0,2], color='lightgreen')\n",
    "axes[0,2].set_title('Activity Pattern by Day of Week', fontweight='bold')\n",
    "axes[0,2].set_ylabel('Number of Records')\n",
    "axes[0,2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Monthly trends\n",
    "axes[1,0].plot(range(len(monthly_trends)), monthly_trends['records'], marker='o', linewidth=2)\n",
    "axes[1,0].set_title('Monthly Trends', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Month Period')\n",
    "axes[1,0].set_ylabel('Number of Records')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Counter comparison\n",
    "counter_activity.plot(x='counter_name', y='total_records', kind='bar', ax=axes[1,1], color='orange')\n",
    "axes[1,1].set_title('Records by Counter', fontweight='bold')\n",
    "axes[1,1].set_ylabel('Total Records')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Installation timeline (since all same date, show coverage)\n",
    "coverage_data = pd.DataFrame({\n",
    "    'Category': ['Monitored', 'Not Monitored'],\n",
    "    'Count': [covered_arr, total_paris_arrondissements - covered_arr]\n",
    "})\n",
    "axes[1,2].pie(coverage_data['Count'], labels=coverage_data['Category'], autopct='%1.1f%%', startangle=90)\n",
    "axes[1,2].set_title('Paris Arrondissement Coverage', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMERCIAL INTELLIGENCE ANALYSIS\n",
      "============================================================\n",
      "KEY FINDINGS:\n",
      "\n",
      "GEOGRAPHIC INTELLIGENCE:\n",
      "   • Strategic Focus: Only 3/20 arrondissements monitored\n",
      "   • High-Value Areas: 10, 13, 28\n",
      "   • Coverage Gap: 17 arrondissements unmonitored\n",
      "\n",
      "ACTIVITY INTELLIGENCE:\n",
      "   • Peak Hour: 15:00 (457 records)\n",
      "   • Peak Day: Wednesday (1,482 records)\n",
      "   • Most Active Location: 28 boulevard Diderot E-O...\n",
      "     └── Arr. 28 (3,296 records)\n",
      "\n",
      "🚴 INFRASTRUCTURE INTELLIGENCE:\n",
      "   • Total Monitoring Points: 4 unique locations\n",
      "   • Data Density: 10,000 total monitoring hours\n",
      "   • Established Infrastructure: Counters operational since 2012\n",
      "   • Long-term Strategic Value: 13+ years of consistent monitoring\n",
      "\n",
      "COMMERCIAL OPPORTUNITIES:\n",
      "   • Proven High-Activity Zones: Arr. 10, 13, 28\n",
      "   • Untapped Markets: 17 arrondissements without bike monitoring\n",
      "   • Peak Advertising Times: 15:00 on Wednesdays\n",
      "   • Infrastructure Investment Priority: Areas with 13+ years of monitoring\n",
      "\n",
      "NEXT ANALYSIS PRIORITIES:\n",
      "   1. Analyze pedestrian zones in same arrondissements\n",
      "   2. Map advertising panels vs. bike counter locations\n",
      "   3. Identify high-activity areas lacking advertising infrastructure\n",
      "   4. Calculate commercial opportunity scores by location\n"
     ]
    }
   ],
   "source": [
    "print(\"COMMERCIAL INTELLIGENCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"KEY FINDINGS:\")\n",
    "\n",
    "# Geographic insights\n",
    "print(f\"\\nGEOGRAPHIC INTELLIGENCE:\")\n",
    "print(f\"   • Strategic Focus: Only {covered_arr}/20 arrondissements monitored\")\n",
    "print(f\"   • High-Value Areas: {', '.join(arr_distribution['arrondissement'].tolist())}\")\n",
    "print(f\"   • Coverage Gap: {total_paris_arrondissements - covered_arr} arrondissements unmonitored\")\n",
    "\n",
    "# Activity insights  \n",
    "peak_hour = hourly_activity.idxmax()\n",
    "peak_day = daily_activity.idxmax()\n",
    "most_active_counter = counter_activity.iloc[0]\n",
    "\n",
    "print(f\"\\nACTIVITY INTELLIGENCE:\")\n",
    "print(f\"   • Peak Hour: {peak_hour}:00 ({hourly_activity[peak_hour]:,} records)\")\n",
    "print(f\"   • Peak Day: {peak_day} ({daily_activity[peak_day]:,} records)\")\n",
    "print(f\"   • Most Active Location: {most_active_counter['counter_name'][:50]}...\")\n",
    "print(f\"     └── Arr. {most_active_counter['arrondissement_clean']} ({most_active_counter['total_records']:,} records)\")\n",
    "\n",
    "# Infrastructure insights\n",
    "total_monitoring_hours = len(bike_data)\n",
    "unique_locations_count = len(unique_locations) if 'unique_locations' in locals() else len(unique_counters)\n",
    "\n",
    "print(f\"\\n🚴 INFRASTRUCTURE INTELLIGENCE:\")\n",
    "print(f\"   • Total Monitoring Points: {unique_locations_count} unique locations\")\n",
    "print(f\"   • Data Density: {total_monitoring_hours:,} total monitoring hours\")\n",
    "print(f\"   • Established Infrastructure: Counters operational since 2012\")\n",
    "print(f\"   • Long-term Strategic Value: 13+ years of consistent monitoring\")\n",
    "\n",
    "# Commercial opportunities\n",
    "print(f\"\\nCOMMERCIAL OPPORTUNITIES:\")\n",
    "print(f\"   • Proven High-Activity Zones: Arr. {', '.join(arr_distribution['arrondissement'].tolist())}\")\n",
    "print(f\"   • Untapped Markets: 17 arrondissements without bike monitoring\")\n",
    "print(f\"   • Peak Advertising Times: {peak_hour}:00 on {peak_day}s\")\n",
    "print(f\"   • Infrastructure Investment Priority: Areas with 13+ years of monitoring\")\n",
    "\n",
    "# Next steps\n",
    "print(f\"\\nNEXT ANALYSIS PRIORITIES:\")\n",
    "print(f\"   1. Analyze pedestrian zones in same arrondissements\")\n",
    "print(f\"   2. Map advertising panels vs. bike counter locations\")\n",
    "print(f\"   3. Identify high-activity areas lacking advertising infrastructure\")\n",
    "print(f\"   4. Calculate commercial opportunity scores by location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced time series analysis\n",
    "print(\"INTERACTIVE TIME SERIES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prepare data for time series\n",
    "bike_data['date'] = bike_data['count_datetime'].dt.date\n",
    "bike_data['week'] = bike_data['count_datetime'].dt.isocalendar().week\n",
    "bike_data['month'] = bike_data['count_datetime'].dt.month\n",
    "\n",
    "# Daily activity trends\n",
    "daily_activity = bike_data.groupby(['date', 'arrondissement_clean']).size().reset_index(name='records')\n",
    "daily_activity['date'] = pd.to_datetime(daily_activity['date'])\n",
    "\n",
    "# Create interactive time series\n",
    "fig = px.line(daily_activity, \n",
    "              x='date', \n",
    "              y='records',\n",
    "              color='arrondissement_clean',\n",
    "              title='Daily Activity Trends by Arrondissement',\n",
    "              labels={'records': 'Activity Level', 'date': 'Date'})\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    hovermode='x unified',\n",
    "    legend_title=\"Arrondissement\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Weekly patterns\n",
    "weekly_activity = bike_data.groupby(['week', 'arrondissement_clean']).size().reset_index(name='records')\n",
    "fig2 = px.bar(weekly_activity, \n",
    "              x='week', \n",
    "              y='records',\n",
    "              color='arrondissement_clean',\n",
    "              title='Weekly Activity Distribution',\n",
    "              barmode='group')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create activity heatmaps\n",
    "print(\" ACTIVITY HEATMAP ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Hour vs Day heatmap\n",
    "hourly_daily = bike_data.groupby(['hour', 'weekday']).size().unstack(fill_value=0)\n",
    "\n",
    "# Reorder days\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hourly_daily = hourly_daily.reindex(columns=day_order)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Heatmap 1: Hour vs Day\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', annot=False, fmt='d')\n",
    "plt.title('🕐 Activity Heatmap: Hour vs Day of Week', fontweight='bold')\n",
    "plt.ylabel('Hour of Day')\n",
    "\n",
    "# Heatmap 2: Month vs Arrondissement\n",
    "month_arr = bike_data.groupby(['month', 'arrondissement_clean']).size().unstack(fill_value=0)\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.heatmap(month_arr, cmap='viridis', annot=True, fmt='d')\n",
    "plt.title('📍 Activity Heatmap: Month vs Arrondissement', fontweight='bold')\n",
    "plt.ylabel('Month')\n",
    "\n",
    "# Heatmap 3: Hour vs Arrondissement\n",
    "hour_arr = bike_data.groupby(['hour', 'arrondissement_clean']).size().unstack(fill_value=0)\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.heatmap(hour_arr, cmap='plasma', annot=False)\n",
    "plt.title('🎯 Activity Heatmap: Hour vs Arrondissement', fontweight='bold')\n",
    "plt.ylabel('Hour of Day')\n",
    "\n",
    "# Heatmap 4: Counter comparison\n",
    "counter_hour = bike_data.groupby(['hour', 'counter_name']).size().unstack(fill_value=0)\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.heatmap(counter_hour, cmap='coolwarm', annot=False)\n",
    "plt.title('🚴 Activity Heatmap: Hour vs Counter', fontweight='bold')\n",
    "plt.ylabel('Hour of Day')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find peak activity windows\n",
    "print(\"\\n PEAK ACTIVITY WINDOWS:\")\n",
    "peak_hours = hourly_daily.max(axis=1).nlargest(5)\n",
    "for hour, activity in peak_hours.items():\n",
    "    peak_day = hourly_daily.loc[hour].idxmax()\n",
    "    print(f\"   • {hour}:00 on {peak_day}: {activity} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive geographic analysis\n",
    "print(\"🗺️ INTERACTIVE GEOGRAPHIC MAPPING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if len(valid_coords) > 0:\n",
    "    # Create activity summary by location\n",
    "    location_activity = valid_coords.groupby(['counter_name', 'latitude', 'longitude', 'arrondissement_clean']).agg({\n",
    "        'count_datetime': ['count', 'min', 'max'],\n",
    "        'hour': lambda x: x.mode().iloc[0] if not x.empty else 0,  # Most common hour\n",
    "        'weekday': lambda x: x.mode().iloc[0] if not x.empty else ''  # Most common day\n",
    "    }).round(4)\n",
    "    \n",
    "    location_activity.columns = ['total_records', 'first_record', 'last_record', 'peak_hour', 'peak_day']\n",
    "    location_activity = location_activity.reset_index()\n",
    "    \n",
    "    # Add activity intensity categories\n",
    "    activity_q75 = location_activity['total_records'].quantile(0.75)\n",
    "    activity_q25 = location_activity['total_records'].quantile(0.25)\n",
    "    \n",
    "    def categorize_activity(records):\n",
    "        if records >= activity_q75:\n",
    "            return 'High Activity'\n",
    "        elif records >= activity_q25:\n",
    "            return 'Medium Activity' \n",
    "        else:\n",
    "            return 'Low Activity'\n",
    "    \n",
    "    location_activity['activity_level'] = location_activity['total_records'].apply(categorize_activity)\n",
    "    \n",
    "    # Create interactive map\n",
    "    fig = px.scatter_mapbox(\n",
    "        location_activity,\n",
    "        lat='latitude',\n",
    "        lon='longitude',\n",
    "        size='total_records',\n",
    "        color='activity_level',\n",
    "        hover_data={\n",
    "            'counter_name': True,\n",
    "            'arrondissement_clean': True,\n",
    "            'total_records': True,\n",
    "            'peak_hour': True,\n",
    "            'peak_day': True\n",
    "        },\n",
    "        color_discrete_map={\n",
    "            'High Activity': '#FF4B4B',\n",
    "            'Medium Activity': '#FFA500', \n",
    "            'Low Activity': '#90EE90'\n",
    "        },\n",
    "        title='Bike Counter Activity Intensity Map',\n",
    "        zoom=11,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"Location Activity Summary:\")\n",
    "    print(location_activity[['counter_name', 'arrondissement_clean', 'total_records', 'activity_level']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced temporal analysis\n",
    "print(\"⏰ ADVANCED TEMPORAL PATTERN ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. Rush hour analysis\n",
    "rush_hours = [7, 8, 9, 17, 18, 19]  # Morning and evening rush\n",
    "bike_data['is_rush_hour'] = bike_data['hour'].isin(rush_hours)\n",
    "rush_analysis = bike_data.groupby(['arrondissement_clean', 'is_rush_hour']).size().unstack()\n",
    "\n",
    "rush_analysis.plot(kind='bar', ax=axes[0,0], color=['lightblue', 'darkblue'])\n",
    "axes[0,0].set_title('Rush Hour vs Non-Rush Hour Activity', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Records')\n",
    "axes[0,0].legend(['Non-Rush', 'Rush Hour'])\n",
    "axes[0,0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. Weekday vs Weekend\n",
    "bike_data['is_weekend'] = bike_data['weekday'].isin(['Saturday', 'Sunday'])\n",
    "weekend_analysis = bike_data.groupby(['arrondissement_clean', 'is_weekend']).size().unstack()\n",
    "\n",
    "weekend_analysis.plot(kind='bar', ax=axes[0,1], color=['green', 'orange'])\n",
    "axes[0,1].set_title('Weekday vs Weekend Activity', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Records')\n",
    "axes[0,1].legend(['Weekday', 'Weekend'])\n",
    "axes[0,1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 3. Monthly trends by location\n",
    "monthly_location = bike_data.groupby(['month', 'counter_name']).size().unstack()\n",
    "monthly_location.plot(ax=axes[0,2], marker='o')\n",
    "axes[0,2].set_title('Monthly Trends by Location', fontweight='bold')\n",
    "axes[0,2].set_ylabel('Records')\n",
    "axes[0,2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 4. Hour distribution by arrondissement\n",
    "for i, arr in enumerate(['10', '13', '28']):\n",
    "    arr_data = bike_data[bike_data['arrondissement_clean'] == arr]\n",
    "    hour_dist = arr_data['hour'].value_counts().sort_index()\n",
    "    \n",
    "    if i == 0:\n",
    "        ax = axes[1,0]\n",
    "        title = f'Hourly Pattern: Arr. {arr} (République)'\n",
    "        color = 'red'\n",
    "    elif i == 1:\n",
    "        ax = axes[1,1] \n",
    "        title = f'Hourly Pattern: Arr. {arr} (Chinatown)'\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        ax = axes[1,2]\n",
    "        title = f'Hourly Pattern: Arr. {arr} (Suburban)'\n",
    "        color = 'green'\n",
    "    \n",
    "    hour_dist.plot(kind='line', ax=ax, marker='o', color=color, linewidth=2, markersize=4)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_ylabel('Records')\n",
    "    ax.set_xlabel('Hour of Day')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical insights\n",
    "print(f\"\\nTEMPORAL INSIGHTS:\")\n",
    "rush_total = bike_data[bike_data['is_rush_hour']].shape[0]\n",
    "non_rush_total = bike_data[~bike_data['is_rush_hour']].shape[0]\n",
    "print(f\"   • Rush hour activity: {rush_total:,} records ({rush_total/len(bike_data)*100:.1f}%)\")\n",
    "print(f\"   • Non-rush activity: {non_rush_total:,} records ({non_rush_total/len(bike_data)*100:.1f}%)\")\n",
    "\n",
    "weekend_total = bike_data[bike_data['is_weekend']].shape[0]\n",
    "weekday_total = bike_data[~bike_data['is_weekend']].shape[0]\n",
    "print(f\"   • Weekend activity: {weekend_total:,} records ({weekend_total/len(bike_data)*100:.1f}%)\")\n",
    "print(f\"   • Weekday activity: {weekday_total:,} records ({weekday_total/len(bike_data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create commercial intelligence summary dashboard\n",
    "print(\"💼 COMMERCIAL INTELLIGENCE DASHBOARD\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate commercial metrics\n",
    "commercial_metrics = {}\n",
    "\n",
    "for arr in ['10', '13', '28']:\n",
    "    arr_data = bike_data[bike_data['arrondissement_clean'] == arr]\n",
    "    \n",
    "    commercial_metrics[arr] = {\n",
    "        'total_activity': len(arr_data),\n",
    "        'peak_hour': arr_data['hour'].mode().iloc[0],\n",
    "        'peak_day': arr_data['weekday'].mode().iloc[0],\n",
    "        'rush_hour_ratio': len(arr_data[arr_data['is_rush_hour']]) / len(arr_data),\n",
    "        'weekend_ratio': len(arr_data[arr_data['is_weekend']]) / len(arr_data),\n",
    "        'activity_consistency': arr_data.groupby('hour').size().std(),\n",
    "        'commercial_score': 0  # Will calculate\n",
    "    }\n",
    "\n",
    "# Calculate commercial scores (higher = better for advertising)\n",
    "for arr in commercial_metrics:\n",
    "    metrics = commercial_metrics[arr]\n",
    "    # Score based on total activity, rush hour presence, and consistency\n",
    "    score = (\n",
    "        metrics['total_activity'] * 0.4 +  # Volume weight\n",
    "        metrics['rush_hour_ratio'] * 2000 +  # Rush hour bonus\n",
    "        (1 - metrics['weekend_ratio']) * 1000 +  # Weekday preference\n",
    "        (1 / (metrics['activity_consistency'] + 1)) * 500  # Consistency bonus\n",
    "    )\n",
    "    commercial_metrics[arr]['commercial_score'] = round(score, 2)\n",
    "\n",
    "# Create dashboard visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Commercial scores comparison\n",
    "scores = [commercial_metrics[arr]['commercial_score'] for arr in ['10', '13', '28']]\n",
    "arr_names = ['République (10)', 'Chinatown (13)', 'Suburban (28)']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "bars = axes[0,0].bar(arr_names, scores, color=colors)\n",
    "axes[0,0].set_title('🏆 Commercial Opportunity Scores', fontweight='bold', fontsize=14)\n",
    "axes[0,0].set_ylabel('Commercial Score')\n",
    "for bar, score in zip(bars, scores):\n",
    "    axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20,\n",
    "                   f'{score:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Rush hour vs regular activity\n",
    "rush_data = []\n",
    "for arr in ['10', '13', '28']:\n",
    "    rush_data.append(commercial_metrics[arr]['rush_hour_ratio'] * 100)\n",
    "\n",
    "x = range(len(arr_names))\n",
    "axes[0,1].bar(x, rush_data, color=colors, alpha=0.7)\n",
    "axes[0,1].set_title('🚗 Rush Hour Activity %', fontweight='bold', fontsize=14)\n",
    "axes[0,1].set_ylabel('Rush Hour %')\n",
    "axes[0,1].set_xticks(x)\n",
    "axes[0,1].set_xticklabels(arr_names, rotation=45)\n",
    "\n",
    "# Activity consistency (lower std = more consistent)\n",
    "consistency_data = [commercial_metrics[arr]['activity_consistency'] for arr in ['10', '13', '28']]\n",
    "axes[1,0].bar(arr_names, consistency_data, color=colors, alpha=0.7)\n",
    "axes[1,0].set_title('📊 Activity Consistency (Lower = Better)', fontweight='bold', fontsize=14)\n",
    "axes[1,0].set_ylabel('Hourly Std Deviation')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Peak activity times\n",
    "peak_hours = [commercial_metrics[arr]['peak_hour'] for arr in ['10', '13', '28']]\n",
    "axes[1,1].bar(arr_names, peak_hours, color=colors, alpha=0.7)\n",
    "axes[1,1].set_title('⏰ Peak Activity Hours', fontweight='bold', fontsize=14)\n",
    "axes[1,1].set_ylabel('Hour (24h format)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].set_ylim(0, 24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print commercial insights\n",
    "print(f\"\\n🎯 COMMERCIAL INTELLIGENCE SUMMARY:\")\n",
    "sorted_areas = sorted(commercial_metrics.items(), key=lambda x: x[1]['commercial_score'], reverse=True)\n",
    "\n",
    "for i, (arr, metrics) in enumerate(sorted_areas):\n",
    "    area_names = {'10': 'République', '13': 'Chinatown', '28': 'Suburban'}\n",
    "    print(f\"\\n{i+1}. 🏛️ ARRONDISSEMENT {arr} ({area_names[arr]}):\")\n",
    "    print(f\"   • Commercial Score: {metrics['commercial_score']:.0f}/10000\")\n",
    "    print(f\"   • Total Activity: {metrics['total_activity']:,} records\")\n",
    "    print(f\"   • Peak Time: {metrics['peak_hour']}:00 on {metrics['peak_day']}s\")\n",
    "    print(f\"   • Rush Hour Activity: {metrics['rush_hour_ratio']*100:.1f}%\")\n",
    "    print(f\"   • Business Days Focus: {(1-metrics['weekend_ratio'])*100:.1f}%\")\n",
    "    \n",
    "    # Commercial recommendation\n",
    "    if metrics['commercial_score'] > 3000:\n",
    "        print(f\"   💰 RECOMMENDATION: Prime advertising location\")\n",
    "    elif metrics['commercial_score'] > 2000:\n",
    "        print(f\"   📈 RECOMMENDATION: Good commercial potential\")\n",
    "    else:\n",
    "        print(f\"   📊 RECOMMENDATION: Emerging market opportunity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIKE COUNTER ANALYSIS SUMMARY\n",
      "============================================================\n",
      "🎯 KEY FINDINGS:\n",
      "   • Total Records: 10000\n",
      "   • Unique Counters: 4\n",
      "   • Arrondissements Covered: 3\n",
      "   • Arrondissements List: ['10', '13', '28']\n",
      "   • Date Range: 2024-05-01 to 2025-06-04\n",
      "   • Peak Hour: 15\n",
      "   • Peak Day: Wednesday\n",
      "   • Monitoring Intensity: 8.1 readings/day avg\n",
      "   • Coverage Percentage: 15.0\n",
      "   • Commercial Opportunity Areas: 17\n",
      "\n",
      "💼 COMMERCIAL INTELLIGENCE:\n",
      "   • High-Value Areas Identified: République (10), Chinatown (13), Suburban (28)\n",
      "   • Peak Commercial Hours: 3 PM on Wednesdays\n",
      "   • Established Infrastructure: 13+ years operational\n",
      "   • Market Gap: 85% of Paris unmonitored\n",
      "\n",
      "EXPORTED:\n",
      "   • bike_counters_summary.json (insights)\n",
      "   • bike_counters_processed.csv (full dataset)\n",
      "\n",
      "Bike Counter Analysis Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"BIKE COUNTER ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Key metrics summary\n",
    "summary_metrics = {\n",
    "    'total_records': len(bike_data),\n",
    "    'unique_counters': len(unique_locations) if 'unique_locations' in locals() else 4,\n",
    "    'arrondissements_covered': 3,\n",
    "    'arrondissements_list': ['10', '13', '28'],\n",
    "    'date_range': '2024-05-01 to 2025-06-04',\n",
    "    'peak_hour': 15,\n",
    "    'peak_day': 'Wednesday',\n",
    "    'monitoring_intensity': '8.1 readings/day avg',\n",
    "    'coverage_percentage': 15.0,\n",
    "    'commercial_opportunity_areas': 17\n",
    "}\n",
    "\n",
    "print(\"🎯 KEY FINDINGS:\")\n",
    "for key, value in summary_metrics.items():\n",
    "    print(f\"   • {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(f\"\\n💼 COMMERCIAL INTELLIGENCE:\")\n",
    "print(f\"   • High-Value Areas Identified: République (10), Chinatown (13), Suburban (28)\")\n",
    "print(f\"   • Peak Commercial Hours: 3 PM on Wednesdays\")\n",
    "print(f\"   • Established Infrastructure: 13+ years operational\")\n",
    "print(f\"   • Market Gap: 85% of Paris unmonitored\")\n",
    "\n",
    "# Save processed data and insights\n",
    "bike_summary = {\n",
    "    'metrics': summary_metrics,\n",
    "    'arrondissement_distribution': arr_distribution.to_dict('records'),\n",
    "    'counter_locations': unique_locations.to_dict('records') if 'unique_locations' in locals() else [],\n",
    "    'hourly_activity': hourly_activity.to_dict(),\n",
    "    'daily_activity': daily_activity.to_dict()\n",
    "}\n",
    "\n",
    "# Export for cross-analysis\n",
    "with open('bike_counters_summary.json', 'w') as f:\n",
    "    json.dump(bike_summary, f, indent=2, default=str)\n",
    "\n",
    "bike_data.to_csv('bike_counters_processed.csv', index=False)\n",
    "print(f\"\\nEXPORTED:\")\n",
    "print(f\"   • bike_counters_summary.json (insights)\")\n",
    "print(f\"   • bike_counters_processed.csv (full dataset)\")\n",
    "print(f\"\\nBike Counter Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
